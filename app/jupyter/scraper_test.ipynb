{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== current_dir  /home/mikuras/004_atelier/003_BrownieAtelier\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "current_dir = os.getcwd()\n",
    "sys.path.append(current_dir)\n",
    "print('=== current_dir ',current_dir)\n",
    "\n",
    "launch = os.path.join(current_dir, '.vscode', 'jupyter_env.json')\n",
    "with open(launch, 'r') as f:\n",
    "    file = f.read()\n",
    "launch_json: dict = json.loads(file)\n",
    "\n",
    "for key,value in launch_json.items():\n",
    "    os.environ[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from errno import EKEYEXPIRED\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import pickle\n",
    "import time\n",
    "import requests\n",
    "from logging import Logger\n",
    "from typing import Any, Union\n",
    "from bs4 import BeautifulSoup as bs4\n",
    "from bs4.element import Tag\n",
    "from bs4.element import ResultSet\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "\n",
    "from prefect_lib.settings import TIMEZONE\n",
    "from prefect_lib.scraper.title_scraper import scraper as title_scraper\n",
    "from prefect_lib.scraper.article_scraper import scraper as airticle_scraper\n",
    "from prefect_lib.scraper.publish_date_scraper import scraper as publish_date_scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''単体テスト用の設定'''\n",
    "test_url = 'https://mainichi.jp/articles/20220605/k00/00m/030/136000c'\n",
    "# 通常サイト用\n",
    "request = requests.get(test_url)\n",
    "# bs4で解析\n",
    "soup: bs4 = bs4(request.text, 'lxml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== scrape_parm === [{'pattern': 1, 'css_selecter': '#articledetail-body > p', 'priority': 1, 'register_date': '2022-06-05T22:00:00+09:00'}]\n",
      "\n",
      "\n",
      "=== result === ({'article': 'バングラデシュ南東部チッタゴン近郊のコンテナ集積地で大規模な火災と爆発が発生し、地元メディアは5日、消防士を含む少なくとも49人が死亡、200人以上が負傷したと報じた。死者は増える恐れがある。爆発は化学物質に引火して起きたとみられる。\\n\\u3000地元メディアなどによると、火災は4日午後10時ごろ起きた。消火活動は難…'}, {'article_scraper': 1})\n"
     ]
    }
   ],
   "source": [
    "scrape_parm = [{\n",
    "    \"pattern\": 1,\n",
    "    \"css_selecter\": \"#articledetail-body > p\",\n",
    "    \"priority\": 1,\n",
    "    \"register_date\":\"2022-06-05T22:00:00+09:00\"\n",
    "}]\n",
    "scrape_parm = sorted(scrape_parm, key=lambda d: d['pattern'], reverse=True)\n",
    "print('\\n\\n=== scrape_parm ===', scrape_parm)\n",
    "\n",
    "result = airticle_scraper(\n",
    "    soup=soup,\n",
    "    scraper='article_scraper',\n",
    "    scrape_parm=scrape_parm,\n",
    ")\n",
    "print('\\n\\n=== result ===', result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00b0d91d220cd2884303810c80f143c1222c3c3704eaa0756460e122a00ee18a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
